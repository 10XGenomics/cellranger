{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to create test files for vdj_asm unit testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tenkit.bam as tk_bam\n",
    "import tenkit.seq as tk_seq\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import pyfasta\n",
    "import pysam\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "NUCS = ['A', 'C', 'G', 'T']\n",
    "\n",
    "UNMAPPED_FIRST_FLAG = int('0b1001101', 2)\n",
    "UNMAPPED_SECOND_FLAG = int('0b10001101', 2)\n",
    "MAPPED_FIRST_FLAG = int('0b1100011', 2)\n",
    "MAPPED_SECOND_FLAG = int('0b10010011', 2)\n",
    "\n",
    "MAPPED_UNPAIRED_FLAG = int('0b1000000', 2)\n",
    "UNMAPPED_UNPAIRED_FLAG = int('0b1000100', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a small bam for testing indexing and bam merging in vdj_asm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tids {'chr5': 4, 'chr4': 3, 'chr3': 2, 'chr2': 1, 'chr1': 0}\n",
      "Split tids [{'chr3': 2, 'chr2': 1, 'chr1': 0}, {'chr5': 2, 'chr4': 1, 'chr3': 0}]\n"
     ]
    }
   ],
   "source": [
    "in_bam_name = '/mnt/park/gemcode/sofia/vdj/master_runs/pipestances/31466/SC_VDJ_PD/SC_VDJ/_VDJ_ASSEMBLER/FILTER_VDJ_READS/fork0/chnk0/files/AAACGGGTCGTTTATC-1.bam'\n",
    "outdir = '/mnt/home/sofia/yard/vdj/data/vdj_asm_test/'\n",
    "\n",
    "out_bam_name = os.path.join(outdir, 'test_index.bam')\n",
    "\n",
    "split_out_bam_names = [os.path.join(outdir, 'test_split1.bam'),\n",
    "                       os.path.join(outdir, 'test_split2.bam')]\n",
    "\n",
    "chroms = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5']\n",
    "lengths = [1000, 1000, 1000, 1000, 1000]\n",
    "\n",
    "# Split chromosomes across two bams. One of the chromosomes will span both bams.\n",
    "split_chroms = [[True, True, True, False, False],\n",
    "                [False, False, True, True, True]]\n",
    "\n",
    "readpairs_per_chrom = 3 # the last pair will always be unmapped\n",
    "\n",
    "# Order of chromosomes in the output file (we want the output to be non-sorted).\n",
    "# The output will have #chroms blocks, each block containing readpairs_per_chrom pairs.\n",
    "chrom_order = np.array([1, 0, 2, 4, 3])\n",
    "\n",
    "in_bam = tk_bam.create_bam_infile(in_bam_name)\n",
    "out_bam, tids = tk_bam.create_bam_outfile(out_bam_name, chroms, lengths)\n",
    "print 'tids', tids\n",
    "\n",
    "split_out_bams = [tk_bam.create_bam_outfile(n,\n",
    "                                            [chroms[i] for i in range(len(sc)) if sc[i]],\n",
    "                                            [lengths[i] for i in range(len(sc)) if sc[i]])\n",
    "                  for (n, sc) in zip(split_out_bam_names, split_chroms)]\n",
    "\n",
    "print 'Split tids', [t for (c, t) in split_out_bams]\n",
    "\n",
    "output_on_common = False\n",
    "\n",
    "for ridx, read in enumerate(in_bam):\n",
    "    if ridx == 2 * readpairs_per_chrom * len(lengths):\n",
    "        break\n",
    "        \n",
    "    if ridx % (2 * readpairs_per_chrom) < 2 * readpairs_per_chrom - 2:\n",
    "        # This is not the last pair of the block.\n",
    "        read.reference_id = chrom_order[ridx / (2 * readpairs_per_chrom)]\n",
    "        read.reference_start = 100 * (ridx % 2)\n",
    "        read.next_reference_id = read.tid\n",
    "        read.next_reference_start = 100 * ((ridx + 1) % 2)\n",
    "        read.flag = MAPPED_FIRST_FLAG if ridx % 2 == 0 else MAPPED_SECOND_FLAG\n",
    "        \n",
    "        assert(not read.is_unmapped)\n",
    "        assert(not read.mate_is_unmapped)\n",
    "        assert(not read.is_secondary)\n",
    "        assert(read.is_paired)\n",
    "        assert((read.is_reverse and ridx % 2 == 1) or (not read.is_reverse and ridx % 2 == 0))\n",
    "    else: \n",
    "        read.reference_id = -1\n",
    "        read.reference_start = 0\n",
    "        read.flag = UNMAPPED_FIRST_FLAG if ridx % 2 == 0 else UNMAPPED_SECOND_FLAG\n",
    "        read.next_reference_id = -1\n",
    "        read.next_reference_start = 0\n",
    "        assert(read.is_paired)\n",
    "        assert(read.is_unmapped)\n",
    "        assert(read.mate_is_unmapped)\n",
    "        \n",
    "    read.qname = 'read{}|||CB|||AAACGGGT|||UB|||ACGT'.format(ridx / 2)\n",
    "    \n",
    "    out_bam.write(read)\n",
    "    \n",
    "    # Decide on which split this read should go\n",
    "    # If the chromosome of the read belongs to the first split, put it there\n",
    "    # unless this is the chromosome that spans both splits.\n",
    "    if split_chroms[0][chrom_order[ridx / (2 * readpairs_per_chrom)]]:\n",
    "        if split_chroms[1][chrom_order[ridx / (2 * readpairs_per_chrom)]]:\n",
    "            if output_on_common:\n",
    "                split_bam = 1\n",
    "            else:\n",
    "                split_bam = 0\n",
    "                # We ouput a pair on the common chromosome. All other pairs \n",
    "                # on that chromosome will go to the second split.\n",
    "                if ridx % 2 == 1:\n",
    "                    output_on_common = True\n",
    "        else:\n",
    "            split_bam = 0\n",
    "    else:\n",
    "        split_bam = 1\n",
    "        \n",
    "    # tids are different!\n",
    "    if read.reference_id > -1:\n",
    "        read.reference_id = split_out_bams[split_bam][1][out_bam.references[read.reference_id]]\n",
    "        read.next_reference_id = read.reference_id\n",
    "        \n",
    "    split_out_bams[split_bam][0].write(read)\n",
    "    \n",
    "out_bam.close()\n",
    "\n",
    "for split_bam in split_out_bams:\n",
    "    split_bam[0].close() \n",
    "    \n",
    "tk_bam.sort_and_index(out_bam_name, re.sub('.bam', '_sorted', out_bam_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test bam for assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_bam_name = '/mnt/home/sofia/yard/vdj/data/vdj_asm_test/test_asm.bam'\n",
    "\n",
    "def unmapped_read(first=True):\n",
    "    read = pysam.AlignedRead()\n",
    "    read.flag = UNMAPPED_FIRST_FLAG if first else UNMAPPED_SECOND_FLAG\n",
    "    read.reference_id = -1\n",
    "    read.reference_start = 0\n",
    "    read.next_reference_id = -1\n",
    "    read.next_reference_start = 0\n",
    "    return read\n",
    "\n",
    "READ_LEN = 150\n",
    "\n",
    "# chromosomes and positions of reads don't matter\n",
    "out_bam, _ = tk_bam.create_bam_outfile(out_bam_name, ['chr1'], [1000])\n",
    "\n",
    "gt_fasta = pyfasta.Fasta('/mnt/opt/meowmix_git/cellranger/vdj/ground_truths/jurkat/contigs.fasta')\n",
    "\n",
    "# We'll create one UMI for each barcode and ground truth sequence combination\n",
    "# For each UMI, we'll get pairs_per_bc read pairs. These will be sequences from\n",
    "# the ground truth, spaced at a given step. So we should be able to reconstruct\n",
    "# the first ((p - 1) * 20) + READ_LEN bases of each ground truth sequence,\n",
    "# where p is the number of pairs.\n",
    "# In addition to the pairs above, we'll also create an unmapped pair which should \n",
    "# be ignored by the assembler.\n",
    "barcodes = ['AAACGGGT', 'CAACGGGT', 'GAACGGGT']\n",
    "umis = ['ACGT', 'ACCC']\n",
    "\n",
    "pairs_per_bc = [5, 4, 3]\n",
    "# Total number of pairs (+ 3 because of one unmapped per BC):\n",
    "# 2 * (5 + 4 + 3) + 3 = 27 (or 54 reads)\n",
    "\n",
    "step = 40\n",
    "\n",
    "for bc_idx, bc in enumerate(barcodes):\n",
    "    # Create one unmapped pair\n",
    "    read1 = unmapped_read(True)\n",
    "    read2 = unmapped_read(False)\n",
    "    read1.seq = 'A' * READ_LEN\n",
    "    read2.seq = read1.seq\n",
    "    read1.qual = chr(63) * len(read1.seq)\n",
    "    read2.qual = chr(63) * len(read2.seq)\n",
    "    \n",
    "    qname = 'read{}:{}|||SEQ|||{}|||CB|||{}|||UB|||AAAA'.format(0, bc, 'FOO', bc)\n",
    "    read1.qname = qname \n",
    "    read2.qname = qname\n",
    "\n",
    "    out_bam.write(read1)\n",
    "    out_bam.write(read2)\n",
    "            \n",
    "    for ridx in range(pairs_per_bc[bc_idx]):\n",
    "        for (seq_name, seq), umi in zip(gt_fasta.iteritems(), umis):\n",
    "            \n",
    "            read1 = pysam.AlignedRead()\n",
    "            read2 = pysam.AlignedRead()\n",
    "            \n",
    "            read1.reference_id = 0\n",
    "            read1.reference_start = 0\n",
    "            read2.reference_id = 0\n",
    "            read2.reference_start = 0\n",
    "            read1.next_reference_id = 0\n",
    "            read1.next_reference_start = 0\n",
    "            read2.next_reference_id = 0\n",
    "            read2.next_reference_start = 0\n",
    "    \n",
    "            read1.flag = MAPPED_FIRST_FLAG\n",
    "            read2.flag = MAPPED_SECOND_FLAG\n",
    "            \n",
    "            read1.seq = str(seq[0:][(step * ridx):(step * ridx + READ_LEN)].upper())\n",
    "            read2.seq = read1.seq\n",
    "            \n",
    "            read1.qual = chr(63) * len(read1.seq)\n",
    "            read2.qual = chr(63) * len(read2.seq)\n",
    "            \n",
    "            qname = 'read{}:{}|||SEQ|||{}|||CB|||{}|||UB|||{}'.format(ridx + 1, bc, seq_name, bc, umi)\n",
    "            read1.qname = qname \n",
    "            read2.qname = qname\n",
    "            \n",
    "            out_bam.write(read1)\n",
    "            out_bam.write(read2)\n",
    "        \n",
    "\n",
    "out_bam.close()\n",
    "\n",
    "# Write the sequences that we expect to reconstruct\n",
    "with open('/mnt/home/sofia/yard/vdj/data/vdj_asm_test/test_asm.fasta', 'w') as out_fasta:\n",
    "    for bc_idx, bc in enumerate(barcodes):\n",
    "        for (seq_name, seq), umi in zip(gt_fasta.iteritems(), umis):\n",
    "            s = seq[0:((pairs_per_bc[bc_idx] - 1) * step + READ_LEN)].upper()\n",
    "            out_fasta.write('>{}_{}\\n'.format(bc, umi))\n",
    "            out_fasta.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test single-end bam for assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_bam_name = '/mnt/home/sofia/yard/vdj/data/vdj_asm_test/test_asm_se.bam'\n",
    "\n",
    "def unmapped_read():\n",
    "    read = pysam.AlignedRead()\n",
    "    read.flag = UNMAPPED_UNPAIRED_FLAG\n",
    "    read.reference_id = -1\n",
    "    read.reference_start = 0\n",
    "    return read\n",
    "\n",
    "READ_LEN = 150\n",
    "\n",
    "# chromosomes and positions of reads don't matter\n",
    "out_bam, _ = tk_bam.create_bam_outfile(out_bam_name, ['chr1'], [1000])\n",
    "\n",
    "gt_fasta = pyfasta.Fasta('/mnt/opt/meowmix_git/cellranger/vdj/ground_truths/jurkat/contigs.fasta')\n",
    "\n",
    "# We'll create one UMI for each barcode and ground truth sequence combination\n",
    "# For each UMI, we'll get reads_per_bc readss. These will be sequences from\n",
    "# the ground truth, spaced at a given step. So we should be able to reconstruct\n",
    "# the first ((p - 1) * 20) + READ_LEN bases of each ground truth sequence,\n",
    "# where p is the number of reads.\n",
    "# I.e. we should reconstruct the same sequences as in the paired case (if we use all \n",
    "# reads).\n",
    "# In addition to the reads above, we'll also create an unmapped read which should \n",
    "# be ignored by the assembler. These unmapped reads will be interleaved with the \n",
    "# mapped ones.\n",
    "barcodes = ['AAACGGGT', 'CAACGGGT', 'GAACGGGT']\n",
    "umis = ['ACGT', 'ACCC']\n",
    "\n",
    "reads_per_bc = [5, 4, 3]\n",
    "# Total number of reads (* 2 because of the unmapped reads and then * 2 by chain):\n",
    "# 2 * 2 * (5 + 4 + 3) = 48\n",
    "\n",
    "step = 40\n",
    "\n",
    "for bc_idx, bc in enumerate(barcodes):\n",
    "    nreads = 0        \n",
    "    for ridx in range(reads_per_bc[bc_idx]):\n",
    "        for (seq_name, seq), umi in zip(gt_fasta.iteritems(), umis):\n",
    "            \n",
    "            read1 = pysam.AlignedRead()\n",
    "            \n",
    "            read1.reference_id = 0\n",
    "            read1.reference_start = 0\n",
    "    \n",
    "            read1.flag = MAPPED_UNPAIRED_FLAG\n",
    "            \n",
    "            read1.seq = str(seq[0:][(step * ridx):(step * ridx + READ_LEN)].upper())\n",
    "            read1.qual = chr(63) * len(read1.seq)\n",
    "            \n",
    "            qname = 'read{}:{}|||SEQ|||{}|||CB|||{}|||UB|||{}'.format(nreads, bc, seq_name, bc, umi)\n",
    "            read1.qname = qname \n",
    "            \n",
    "            # Create one unmapped read\n",
    "            read2 = unmapped_read()\n",
    "            read2.seq = 'A' * READ_LEN\n",
    "            read2.qual = chr(63) * len(read2.seq)\n",
    "\n",
    "            qname = 'read{}:{}|||SEQ|||{}|||CB|||{}|||UB|||AAAA'.format(nreads + 1, bc, seq_name, bc)\n",
    "            read2.qname = qname\n",
    "\n",
    "            out_bam.write(read1)\n",
    "            out_bam.write(read2)\n",
    "            nreads += 2\n",
    "            \n",
    "out_bam.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input data for testing the base quality computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "import tenkit.fasta as tk_fasta\n",
    "import tenkit.seq as tk_seq\n",
    "\n",
    "def create_random_seq(seq_len, letters = NUCS):\n",
    "    output_seq_letters = np.random.choice(np.arange(4), seq_len, replace=True)\n",
    "    return ''.join([letters[i] for i in output_seq_letters])\n",
    "\n",
    "def write_reads(gt_seq, start, read_len, umi, qidx, fq1, fq2, fq, error_rate=0):\n",
    "    seq1 = gt_seq[start:(start + read_len)]\n",
    "    seq2 = gt_seq[(start + read_len):(start + 2 * read_len)] \n",
    "    \n",
    "    if error_rate > 0:\n",
    "        seq1 = ''.join([np.random.choice(NUCS, 1)[0] if np.random.rand() < error_rate else s for s in seq1])\n",
    "        seq2 = ''.join([np.random.choice(NUCS, 1)[0] if np.random.rand() < error_rate else s for s in seq2])\n",
    "        \n",
    "    quals = chr(60) * len(seq1)\n",
    "    \n",
    "    bc = 'ACGTACGT'\n",
    "    qname = 'read{}|||CB|||{}|||UB|||{}'.format(qidx, bc, umi)\n",
    "    tk_fasta.write_read_fastq(fq1, qname, seq1, quals)\n",
    "    tk_fasta.write_read_fastq(fq2, qname, tk_seq.get_rev_comp(seq2), quals)\n",
    "    \n",
    "    tk_fasta.write_read_fastq(fq, qname, seq1, quals)\n",
    "    qname = 'read{}b|||CB|||{}|||UB|||{}'.format(qidx, bc, umi)\n",
    "    tk_fasta.write_read_fastq(fq, qname, seq2, quals)\n",
    "    \n",
    "np.random.seed(1)\n",
    "\n",
    "output_seq_len = 1000\n",
    "output_seq = create_random_seq(output_seq_len)\n",
    "\n",
    "outdir = '/mnt/home/sofia/yard/vdj/data/vdj_asm_test/base_quals/'\n",
    "\n",
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)\n",
    "    \n",
    "out_fasta_name = os.path.join(outdir, 'test_base_quals.fasta')\n",
    "out_fq1_name = os.path.join(outdir, 'test_base_quals_1.fastq')\n",
    "out_fq2_name = os.path.join(outdir, 'test_base_quals_2.fastq')\n",
    "out_fq_name = os.path.join(outdir, 'test_base_quals.fastq')\n",
    "\n",
    "with open(out_fasta_name, 'w') as f:\n",
    "    tk_fasta.write_read_fasta(f, 'random_seq', output_seq)\n",
    "    \n",
    "read_len = 100\n",
    "\n",
    "with open(out_fq1_name, 'w') as fq1, open(out_fq2_name, 'w') as fq2, open(out_fq_name, 'w') as fq:\n",
    "    write_reads(output_seq, 0, read_len, 'ACGT', 0, fq1, fq2, fq)\n",
    "    write_reads(output_seq, 200, read_len, 'ACGT', 1, fq1, fq2, fq)\n",
    "    write_reads(output_seq, 0, read_len, 'CCCC', 2, fq1, fq2, fq)\n",
    "    \n",
    "    write_reads(output_seq, 400, read_len, 'CCCC', 3, fq1, fq2, fq, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'C', 'G', 'T', 'A']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1 = 'ACGTA'\n",
    "[np.random.choice(letters, 1)[0] if np.random.rand() < 0.1 else s for s in seq1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
